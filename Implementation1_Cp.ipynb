{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSVs\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get training, validation and test data\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(\"./PA1_train.csv\")\n",
    "    dev = pd.read_csv(\"./PA1_dev.csv\")\n",
    "    test = pd.read_csv(\"./PA1_test.csv\")\n",
    "    return train,dev,test\n",
    "\n",
    "#Add bias\n",
    "def add_bias(df):\n",
    "    \"\"\"\n",
    "    Add dummy variable to control intercept\n",
    "    \"\"\"\n",
    "    df[\"dummy\"] = 1\n",
    "    return df\n",
    "\n",
    "#Seperate Features from response\n",
    "def seperate(df_train):\n",
    "    \"\"\"\n",
    "    input: dataframe\n",
    "    \"\"\"\n",
    "    #Grab all continuous features\n",
    "    x = df_train.iloc[:,0:-1]\n",
    "    #Split dates\n",
    "    x = split_date(x)\n",
    "    x = x.drop([\"date\"], axis=1)\n",
    "    #Grab response y\n",
    "    y = df_train.iloc[:,-1]\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "    \n",
    "#Add new features [Month, Day, Year]\n",
    "def split_date(df_train):\n",
    "    \"\"\"\n",
    "    splits date into seperate features\n",
    "    input: dataframe\n",
    "    \"\"\"\n",
    "    print(\"Splitting date...\")\n",
    "    for i in range(0,len(df_train)):\n",
    "        df_train.loc[i,\"month\"] = int(df_train.loc[i,\"date\"].split(\"/\")[0])\n",
    "        df_train.loc[i,\"day\"] = int(df_train.loc[i,\"date\"].split(\"/\")[1])\n",
    "        df_train.loc[i,\"year\"] = int(df_train.loc[i,\"date\"].split(\"/\")[2])\n",
    "    print(\"Done\")\n",
    "    return df_train\n",
    "\n",
    "#Normalize data\n",
    "def normalize(df1):\n",
    "    \"\"\"\n",
    "    Normalizes feature matrix\n",
    "    input: feature df\n",
    "    \"\"\"\n",
    "    print(\"Normalizing...\")\n",
    "    x = (df1 - np.min(df1))/(np.max(df1) - np.min(df1))\n",
    "    print(\"DONE\")\n",
    "    return x\n",
    "\n",
    "#Linear regression function\n",
    "def linear_regress(x,y,eta,t,lamb):\n",
    "    \"\"\"\n",
    "    x: input/features\n",
    "    y: opuput\n",
    "    eta: learning rate\n",
    "    t: iterations\n",
    "    lamb: regularization constant\n",
    "    \"\"\"\n",
    "    print(f'#Learning Rate : {eta}#####')\n",
    "    \n",
    "    n = 0\n",
    "    e = np.zeros(len(y))\n",
    "    errors = []\n",
    "    gradient = []\n",
    "    \n",
    "    #Initialize weights [w] and predictions [y_hat]\n",
    "    w = np.zeros(len(x[0]))\n",
    "    \n",
    "    cur_grad = 0\n",
    "    prev_grad = 0\n",
    "     \n",
    "    while n<t:\n",
    "        #Initialize gradient for each epoch\n",
    "        gradient_vector = np.zeros(len(x[0]))\n",
    "        \n",
    "        \"\"\"        \n",
    "        #Traverse through each data point   \n",
    "        for i in range(len(x)):\n",
    "            #Predicted value\n",
    "            y_hat = np.dot(w.T,x[i])\n",
    "\n",
    "            #Error\n",
    "            e[i] = ((y[i] - y_hat)**2)\n",
    "            \n",
    "            \n",
    "            #Regularization\n",
    "            if np.dot(w.T,w) == 0:\n",
    "                r = 0\n",
    "            else:\n",
    "                r = (np.dot(w.T,w))**0.5\n",
    "            \n",
    "            #Traverse through each feature to update corresponding weights\n",
    "            #for j in range(len(x[0])):\n",
    "            #    gradient_vector[j] += ((-2)*(y[i] - y_hat)*x[i,j]) + (2*lamb*r)\n",
    "            gradient_vector += \n",
    "        \"\"\"\n",
    "        \n",
    "        #y_hat = np.matmul(w.T, x)\n",
    "        y_hat = np.matmul(x, w)\n",
    "        e = (y-y_hat)**2\n",
    "        \n",
    "        gradient_vector = (-2)*np.matmul(x.T, (y-y_hat))  \n",
    "        \n",
    "        #Update weights\n",
    "        w -=  eta*gradient_vector\n",
    "        #Calculate SSE\n",
    "        errors.append(sum(e))\n",
    "        #Norm of gradient\n",
    "        convergence_criteria = np.dot(gradient_vector.T,gradient_vector)**0.5\n",
    "        gradient.append(convergence_criteria)\n",
    "        \n",
    "        ####\n",
    "        #print(f'#####Iteration : {n+1}#####')\n",
    "        #print(f'Gradient : {gradient[n]}')\n",
    "\n",
    "        \n",
    "        ####\n",
    "        if (gradient[n]/(10**9)) > 1 and (n+1) <= 6:\n",
    "            t = 8\n",
    "        \n",
    "        n += 1\n",
    "        if convergence_criteria < 0.5:\n",
    "            print(f'#Iteration : {n}#####')\n",
    "            print(f'Gradient : {gradient[n-1]}')\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            return w,errors,gradient, n\n",
    "        if (n) % 5000 == 0:\n",
    "            print(f'#Iteration : {n}#####')\n",
    "            print(f'Gradient : {gradient[n-1]}')\n",
    "\n",
    "    print(f'#Iteration : {n}#####')\n",
    "    print(f'Gradient : {gradient[n-1]}')\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    return w,errors,gradient, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting date...\n",
      "Done\n",
      "Normalizing...\n",
      "DONE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.246849</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368687</td>\n",
       "      <td>0.761782</td>\n",
       "      <td>0.394979</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.234244</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631313</td>\n",
       "      <td>0.683127</td>\n",
       "      <td>0.112971</td>\n",
       "      <td>0.318584</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.707093</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.226549</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.141807</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.515522</td>\n",
       "      <td>0.300418</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.363445</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.690043</td>\n",
       "      <td>0.335565</td>\n",
       "      <td>0.361062</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.231092</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.526621</td>\n",
       "      <td>0.298745</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.007566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843434</td>\n",
       "      <td>0.540454</td>\n",
       "      <td>0.169874</td>\n",
       "      <td>0.138053</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.122899</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.966061</td>\n",
       "      <td>0.158159</td>\n",
       "      <td>0.304425</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.145607</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.192227</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297089</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.327434</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dummy  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0         1   0.09375   0.275862     0.246849  0.005715     0.4         0.0   \n",
       "1         1   0.03125   0.275862     0.234244  0.002682     0.0         0.0   \n",
       "2         1   0.12500   0.172414     0.134454  0.001471     0.2         0.0   \n",
       "3         1   0.09375   0.172414     0.141807  0.005469     0.0         0.0   \n",
       "4         1   0.15625   0.241379     0.363445  0.006426     0.0         0.0   \n",
       "...     ...       ...        ...          ...       ...     ...         ...   \n",
       "9995      1   0.09375   0.275862     0.231092  0.013111     0.4         0.0   \n",
       "9996      1   0.00000   0.068966     0.044118  0.007566     0.0         0.0   \n",
       "9997      1   0.06250   0.137931     0.122899  0.004200     0.0         0.0   \n",
       "9998      1   0.06250   0.241379     0.157563  0.000804     0.8         0.0   \n",
       "9999      1   0.09375   0.275862     0.192227  0.005346     0.4         0.0   \n",
       "\n",
       "      view  condition     grade  ...  yr_built  yr_renovated   zipcode  \\\n",
       "0      0.0       0.50  0.555556  ...  0.773913           0.0  0.368687   \n",
       "1      0.0       1.00  0.444444  ...  0.226087           0.0  0.631313   \n",
       "2      0.0       0.50  0.444444  ...  0.017391           0.0  0.722222   \n",
       "3      0.0       0.75  0.444444  ...  0.600000           0.0  0.292929   \n",
       "4      0.5       1.00  0.555556  ...  0.539130           0.0  0.035354   \n",
       "...    ...        ...       ...  ...       ...           ...       ...   \n",
       "9995   0.0       1.00  0.333333  ...  0.504348           0.0  0.292929   \n",
       "9996   0.0       0.50  0.222222  ...  0.365217           0.0  0.843434   \n",
       "9997   0.0       1.00  0.333333  ...  0.530435           0.0  0.777778   \n",
       "9998   0.0       0.50  0.444444  ...  0.939130           0.0  0.515152   \n",
       "9999   0.0       0.50  0.444444  ...  0.756522           0.0  0.000000   \n",
       "\n",
       "           lat      long  sqft_living15  sqft_lot15     month       day  year  \n",
       "0     0.761782  0.394979       0.400000    0.011601  0.545455  0.266667   0.0  \n",
       "1     0.683127  0.112971       0.318584    0.004985  0.545455  0.566667   0.0  \n",
       "2     0.707093  0.174059       0.226549    0.003837  0.545455  0.200000   0.0  \n",
       "3     0.515522  0.300418       0.212389    0.011556  0.272727  0.900000   1.0  \n",
       "4     0.690043  0.335565       0.361062    0.011188  0.727273  0.100000   0.0  \n",
       "...        ...       ...            ...         ...       ...       ...   ...  \n",
       "9995  0.526621  0.298745       0.353982    0.006746  0.727273  0.833333   0.0  \n",
       "9996  0.540454  0.169874       0.138053    0.007440  0.454545  0.100000   0.0  \n",
       "9997  0.966061  0.158159       0.304425    0.008033  0.181818  0.533333   1.0  \n",
       "9998  0.800708  0.145607       0.217699    0.001188  0.909091  0.566667   0.0  \n",
       "9999  0.297089  0.205021       0.327434    0.009782  0.363636  0.033333   0.0  \n",
       "\n",
       "[10000 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####DATA PREP#####\n",
    "\n",
    "#load csv\n",
    "df_train,df_dev,df_test = get_data()\n",
    "#Drop ID Feature\n",
    "df_train = df_train.drop(\"id\", axis=1)\n",
    "\n",
    "#Grab features and Response\n",
    "x,y = seperate(df_train)\n",
    "\n",
    "#Normalize continuous features\n",
    "x_norm_df = normalize(x)\n",
    "#Add Bias \n",
    "x_norm_df = add_bias(x_norm_df)\n",
    "x_norm = x_norm_df.values\n",
    "\n",
    "x_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Learning Rate : 1#####\n",
      "#Iteration : 8#####\n",
      "Gradient : 1.472848576615808e+39\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 0.1#####\n",
      "#Iteration : 8#####\n",
      "Gradient : 1.471497501080642e+32\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 0.01#####\n",
      "#Iteration : 8#####\n",
      "Gradient : 1.4580450660796086e+25\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 0.001#####\n",
      "#Iteration : 8#####\n",
      "Gradient : 1.3292132020270461e+18\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 0.0001#####\n",
      "#Iteration : 8#####\n",
      "Gradient : 48934078876.18486\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 1e-05#####\n",
      "#Iteration : 5000#####\n",
      "Gradient : 66.01152097735797\n",
      "#Iteration : 10000#####\n",
      "Gradient : 38.74538928031949\n",
      "#Iteration : 15000#####\n",
      "Gradient : 23.6693192645556\n",
      "#Iteration : 20000#####\n",
      "Gradient : 14.82837923574096\n",
      "#Iteration : 25000#####\n",
      "Gradient : 9.656090738972635\n",
      "#Iteration : 30000#####\n",
      "Gradient : 6.624495278126791\n",
      "#Iteration : 35000#####\n",
      "Gradient : 4.814123451455354\n",
      "#Iteration : 40000#####\n",
      "Gradient : 3.6821167624107236\n",
      "#Iteration : 45000#####\n",
      "Gradient : 2.923342962753532\n",
      "#Iteration : 50000#####\n",
      "Gradient : 2.375962307231736\n",
      "#Iteration : 55000#####\n",
      "Gradient : 1.9570325671990056\n",
      "#Iteration : 60000#####\n",
      "Gradient : 1.623589502585369\n",
      "#Iteration : 65000#####\n",
      "Gradient : 1.3520126995642912\n",
      "#Iteration : 70000#####\n",
      "Gradient : 1.1280262467639544\n",
      "#Iteration : 75000#####\n",
      "Gradient : 0.9420665125147191\n",
      "#Iteration : 80000#####\n",
      "Gradient : 0.7871518131581194\n",
      "#Iteration : 85000#####\n",
      "Gradient : 0.6578756324348741\n",
      "#Iteration : 90000#####\n",
      "Gradient : 0.5499000617898523\n",
      "#Iteration : 92654#####\n",
      "Gradient : 0.4999976273236073\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 1e-06#####\n",
      "#Iteration : 5000#####\n",
      "Gradient : 714.1896249293598\n",
      "#Iteration : 10000#####\n",
      "Gradient : 340.6241966367171\n",
      "#Iteration : 15000#####\n",
      "Gradient : 208.75144249100748\n",
      "#Iteration : 20000#####\n",
      "Gradient : 146.7719158907377\n",
      "#Iteration : 25000#####\n",
      "Gradient : 114.23637674740205\n",
      "#Iteration : 30000#####\n",
      "Gradient : 95.66432682081637\n",
      "#Iteration : 35000#####\n",
      "Gradient : 84.15341249620475\n",
      "#Iteration : 40000#####\n",
      "Gradient : 76.36352274210768\n",
      "#Iteration : 45000#####\n",
      "Gradient : 70.6060325177624\n",
      "#Iteration : 50000#####\n",
      "Gradient : 66.00825143184981\n",
      "#Iteration : 55000#####\n",
      "Gradient : 62.111583518024915\n",
      "#Iteration : 60000#####\n",
      "Gradient : 58.67010928286344\n",
      "#Iteration : 65000#####\n",
      "Gradient : 55.5482977972675\n",
      "#Iteration : 70000#####\n",
      "Gradient : 52.668711362367944\n",
      "#Iteration : 75000#####\n",
      "Gradient : 49.98503699107216\n",
      "#Iteration : 80000#####\n",
      "Gradient : 47.46800858659846\n",
      "#Iteration : 85000#####\n",
      "Gradient : 45.0979443548243\n",
      "#Iteration : 90000#####\n",
      "Gradient : 42.86071879587715\n",
      "#Iteration : 95000#####\n",
      "Gradient : 40.7455437151927\n",
      "#Iteration : 100000#####\n",
      "Gradient : 38.74371798295938\n",
      "#Iteration : 105000#####\n",
      "Gradient : 36.8479057215684\n",
      "#Iteration : 110000#####\n",
      "Gradient : 35.051708558214045\n",
      "#Iteration : 115000#####\n",
      "Gradient : 33.349405023897546\n",
      "#Iteration : 120000#####\n",
      "Gradient : 31.73578706149937\n",
      "#Iteration : 125000#####\n",
      "Gradient : 30.20605421519528\n",
      "#Iteration : 130000#####\n",
      "Gradient : 28.755742842766416\n",
      "#Iteration : 135000#####\n",
      "Gradient : 27.380677057051017\n",
      "#Iteration : 140000#####\n",
      "Gradient : 26.076933438059704\n",
      "#Iteration : 145000#####\n",
      "Gradient : 24.840814659066925\n",
      "#Iteration : 150000#####\n",
      "Gradient : 23.668829009424023\n",
      "#Iteration : 155000#####\n",
      "Gradient : 22.557673908404276\n",
      "#Iteration : 160000#####\n",
      "Gradient : 21.50422218792275\n",
      "#Iteration : 165000#####\n",
      "Gradient : 20.505510348961362\n",
      "#Iteration : 170000#####\n",
      "Gradient : 19.558728267005506\n",
      "#Iteration : 175000#####\n",
      "Gradient : 18.661209995307818\n",
      "#Iteration : 180000#####\n",
      "Gradient : 17.810425427330742\n",
      "#Iteration : 185000#####\n",
      "Gradient : 17.003972653471163\n",
      "#Iteration : 190000#####\n",
      "Gradient : 16.23957089596755\n",
      "#Iteration : 195000#####\n",
      "Gradient : 15.515053938519657\n",
      "#Iteration : 200000#####\n",
      "Gradient : 14.828363989144647\n",
      "#Iteration : 205000#####\n",
      "Gradient : 14.177545929816942\n",
      "#Iteration : 210000#####\n",
      "Gradient : 13.560741916797905\n",
      "#Iteration : 215000#####\n",
      "Gradient : 12.976186302798416\n",
      "#Iteration : 220000#####\n",
      "Gradient : 12.42220085724234\n",
      "#Iteration : 225000#####\n",
      "Gradient : 11.897190264575357\n",
      "#Iteration : 230000#####\n",
      "Gradient : 11.399637883226497\n",
      "#Iteration : 235000#####\n",
      "Gradient : 10.928101749816342\n",
      "#Iteration : 240000#####\n",
      "Gradient : 10.48121081464057\n",
      "#Iteration : 245000#####\n",
      "Gradient : 10.057661395585312\n",
      "#Iteration : 250000#####\n",
      "Gradient : 9.656213838438585\n",
      "#Iteration : 255000#####\n",
      "Gradient : 9.275689372191103\n",
      "#Iteration : 260000#####\n",
      "Gradient : 8.91496714842648\n",
      "#Iteration : 265000#####\n",
      "Gradient : 8.572981454237226\n",
      "#Iteration : 270000#####\n",
      "Gradient : 8.248719088436118\n",
      "#Iteration : 275000#####\n",
      "Gradient : 7.94121689105557\n",
      "#Iteration : 280000#####\n",
      "Gradient : 7.649559416353335\n",
      "#Iteration : 285000#####\n",
      "Gradient : 7.372876739753586\n",
      "#Iteration : 290000#####\n",
      "Gradient : 7.110342389365563\n",
      "#Iteration : 295000#####\n",
      "Gradient : 6.861171392966911\n",
      "#Iteration : 300000#####\n",
      "Gradient : 6.6246184316013155\n",
      "#Iteration : 305000#####\n",
      "Gradient : 6.399976091253293\n",
      "#Iteration : 310000#####\n",
      "Gradient : 6.1865732044340795\n",
      "#Iteration : 315000#####\n",
      "Gradient : 5.983773273898647\n",
      "#Iteration : 320000#####\n",
      "Gradient : 5.790972971189053\n",
      "#Iteration : 325000#####\n",
      "Gradient : 5.607600703189348\n",
      "#Iteration : 330000#####\n",
      "Gradient : 5.433115240417328\n",
      "#Iteration : 335000#####\n",
      "Gradient : 5.267004401354645\n",
      "#Iteration : 340000#####\n",
      "Gradient : 5.108783787692682\n",
      "#Iteration : 345000#####\n",
      "Gradient : 4.957995565987342\n",
      "#Iteration : 350000#####\n",
      "Gradient : 4.814207291793991\n",
      "#Iteration : 355000#####\n",
      "Gradient : 4.67701077295515\n",
      "#Iteration : 360000#####\n",
      "Gradient : 4.546020969249933\n",
      "#Iteration : 365000#####\n",
      "Gradient : 4.420874926153938\n",
      "#Iteration : 370000#####\n",
      "Gradient : 4.301230740928777\n",
      "#Iteration : 375000#####\n",
      "Gradient : 4.1867665596899615\n",
      "#Iteration : 380000#####\n",
      "Gradient : 4.077179604481683\n",
      "#Iteration : 385000#####\n",
      "Gradient : 3.9721852297027813\n",
      "#Iteration : 390000#####\n",
      "Gradient : 3.8715160074915747\n",
      "#Iteration : 395000#####\n",
      "Gradient : 3.774920841880794\n",
      "#Iteration : 400000#####\n",
      "Gradient : 3.6821641116924635\n",
      "#Iteration : 405000#####\n",
      "Gradient : 3.5930248422366615\n",
      "#Iteration : 410000#####\n",
      "Gradient : 3.5072959059415845\n",
      "#Iteration : 415000#####\n",
      "Gradient : 3.4247832520596906\n",
      "#Iteration : 420000#####\n",
      "Gradient : 3.3453051655820425\n",
      "#Iteration : 425000#####\n",
      "Gradient : 3.2686915554475866\n",
      "#Iteration : 430000#####\n",
      "Gradient : 3.194783272074632\n",
      "#Iteration : 435000#####\n",
      "Gradient : 3.1234314541583443\n",
      "#Iteration : 440000#####\n",
      "Gradient : 3.054496904595852\n",
      "#Iteration : 445000#####\n",
      "Gradient : 2.987849495295173\n",
      "#Iteration : 450000#####\n",
      "Gradient : 2.9233676005378433\n",
      "#Iteration : 455000#####\n",
      "Gradient : 2.8609375584579912\n",
      "#Iteration : 460000#####\n",
      "Gradient : 2.8004531601174443\n",
      "#Iteration : 465000#####\n",
      "Gradient : 2.7418151655661136\n",
      "#Iteration : 470000#####\n",
      "Gradient : 2.6849308462016253\n",
      "#Iteration : 475000#####\n",
      "Gradient : 2.629713552672782\n",
      "#Iteration : 480000#####\n",
      "Gradient : 2.576082307512245\n",
      "#Iteration : 485000#####\n",
      "Gradient : 2.5239614216396764\n",
      "#Iteration : 490000#####\n",
      "Gradient : 2.473280133830051\n",
      "#Iteration : 495000#####\n",
      "Gradient : 2.423972272221816\n",
      "#Iteration : 500000#####\n",
      "Gradient : 2.3759759369136835\n",
      "#Iteration : 505000#####\n",
      "Gradient : 2.3292332026928406\n",
      "#Iteration : 510000#####\n",
      "Gradient : 2.2836898409285586\n",
      "#Iteration : 515000#####\n",
      "Gradient : 2.2392950596765533\n",
      "#Iteration : 520000#####\n",
      "Gradient : 2.1960012610436865\n",
      "#Iteration : 525000#####\n",
      "Gradient : 2.1537638148835643\n",
      "#Iteration : 530000#####\n",
      "Gradient : 2.1125408479087624\n",
      "#Iteration : 535000#####\n",
      "Gradient : 2.072293047336067\n",
      "#Iteration : 540000#####\n",
      "Gradient : 2.032983478203377\n",
      "#Iteration : 545000#####\n",
      "Gradient : 1.994577413532306\n",
      "#Iteration : 550000#####\n",
      "Gradient : 1.957042176536962\n",
      "#Iteration : 555000#####\n",
      "Gradient : 1.9203469941190519\n",
      "#Iteration : 560000#####\n",
      "Gradient : 1.8844628609185632\n",
      "#Iteration : 565000#####\n",
      "Gradient : 1.8493624132276372\n",
      "#Iteration : 570000#####\n",
      "Gradient : 1.8150198121095695\n",
      "#Iteration : 575000#####\n",
      "Gradient : 1.78141063509692\n",
      "#Iteration : 580000#####\n",
      "Gradient : 1.748511775882644\n",
      "#Iteration : 585000#####\n",
      "Gradient : 1.7163013514448073\n",
      "#Iteration : 590000#####\n",
      "Gradient : 1.684758616083554\n",
      "#Iteration : 595000#####\n",
      "Gradient : 1.6538638818782154\n",
      "#Iteration : 600000#####\n",
      "Gradient : 1.6235984451029253\n",
      "#Iteration : 605000#####\n",
      "Gradient : 1.593944518168906\n",
      "#Iteration : 610000#####\n",
      "Gradient : 1.564885166689558\n",
      "#Iteration : 615000#####\n",
      "Gradient : 1.5364042512913774\n",
      "#Iteration : 620000#####\n",
      "Gradient : 1.5084863738166618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration : 625000#####\n",
      "Gradient : 1.4811168275932023\n",
      "#Iteration : 630000#####\n",
      "Gradient : 1.4542815514624428\n",
      "#Iteration : 635000#####\n",
      "Gradient : 1.4279670872843522\n",
      "#Iteration : 640000#####\n",
      "Gradient : 1.4021605406541413\n",
      "#Iteration : 645000#####\n",
      "Gradient : 1.376849544586504\n",
      "#Iteration : 650000#####\n",
      "Gradient : 1.3520222259397217\n",
      "#Iteration : 655000#####\n",
      "Gradient : 1.327667174369019\n",
      "#Iteration : 660000#####\n",
      "Gradient : 1.303773413615757\n",
      "#Iteration : 665000#####\n",
      "Gradient : 1.2803303749493167\n",
      "#Iteration : 670000#####\n",
      "Gradient : 1.2573278725970725\n",
      "#Iteration : 675000#####\n",
      "Gradient : 1.2347560810066898\n",
      "#Iteration : 680000#####\n",
      "Gradient : 1.2126055137986405\n",
      "#Iteration : 685000#####\n",
      "Gradient : 1.19086700427725\n",
      "#Iteration : 690000#####\n",
      "Gradient : 1.169531687377652\n",
      "#Iteration : 695000#####\n",
      "Gradient : 1.1485909829373913\n",
      "#Iteration : 700000#####\n",
      "Gradient : 1.1280365801889554\n",
      "#Iteration : 705000#####\n",
      "Gradient : 1.107860423377036\n",
      "#Iteration : 710000#####\n",
      "Gradient : 1.0880546984125619\n",
      "#Iteration : 715000#####\n",
      "Gradient : 1.0686118204825843\n",
      "#Iteration : 720000#####\n",
      "Gradient : 1.04952442254142\n",
      "#Iteration : 725000#####\n",
      "Gradient : 1.0307853446129867\n",
      "#Iteration : 730000#####\n",
      "Gradient : 1.0123876238419065\n",
      "#Iteration : 735000#####\n",
      "Gradient : 0.994324485234558\n",
      "#Iteration : 740000#####\n",
      "Gradient : 0.9765893330357212\n",
      "#Iteration : 745000#####\n",
      "Gradient : 0.9591757426920553\n",
      "#Iteration : 750000#####\n",
      "Gradient : 0.9420774533563678\n",
      "#Iteration : 755000#####\n",
      "Gradient : 0.9252883608899594\n",
      "#Iteration : 760000#####\n",
      "Gradient : 0.9088025113261979\n",
      "#Iteration : 765000#####\n",
      "Gradient : 0.8926140947574555\n",
      "#Iteration : 770000#####\n",
      "Gradient : 0.8767174396147406\n",
      "#Iteration : 775000#####\n",
      "Gradient : 0.8611070073086569\n",
      "#Iteration : 780000#####\n",
      "Gradient : 0.8457773872044273\n",
      "#Iteration : 785000#####\n",
      "Gradient : 0.8307232919051909\n",
      "#Iteration : 790000#####\n",
      "Gradient : 0.8159395528206194\n",
      "#Iteration : 795000#####\n",
      "Gradient : 0.8014211159991105\n",
      "#Iteration : 800000#####\n",
      "Gradient : 0.7871630382032246\n",
      "#Iteration : 805000#####\n",
      "Gradient : 0.7731604832109689\n",
      "#Iteration : 810000#####\n",
      "Gradient : 0.7594087183252514\n",
      "#Iteration : 815000#####\n",
      "Gradient : 0.745903111076646\n",
      "#Iteration : 820000#####\n",
      "Gradient : 0.7326391261055288\n",
      "#Iteration : 825000#####\n",
      "Gradient : 0.7196123222091223\n",
      "#Iteration : 830000#####\n",
      "Gradient : 0.7068183495430348\n",
      "#Iteration : 835000#####\n",
      "Gradient : 0.6942529469656165\n",
      "#Iteration : 840000#####\n",
      "Gradient : 0.6819119395143612\n",
      "#Iteration : 845000#####\n",
      "Gradient : 0.6697912360055455\n",
      "#Iteration : 850000#####\n",
      "Gradient : 0.6578868267488817\n",
      "#Iteration : 855000#####\n",
      "Gradient : 0.6461947813679219\n",
      "#Iteration : 860000#####\n",
      "Gradient : 0.6347112467203877\n",
      "#Iteration : 865000#####\n",
      "Gradient : 0.6234324449104532\n",
      "#Iteration : 870000#####\n",
      "Gradient : 0.6123546713873251\n",
      "#Iteration : 875000#####\n",
      "Gradient : 0.6014742931246003\n",
      "#Iteration : 880000#####\n",
      "Gradient : 0.5907877468748343\n",
      "#Iteration : 885000#####\n",
      "Gradient : 0.5802915374938499\n",
      "#Iteration : 890000#####\n",
      "Gradient : 0.5699822363313503\n",
      "#Iteration : 895000#####\n",
      "Gradient : 0.5598564796833083\n",
      "#Iteration : 900000#####\n",
      "Gradient : 0.5499109673020379\n",
      "#Iteration : 905000#####\n",
      "Gradient : 0.5401424609605184\n",
      "#Iteration : 910000#####\n",
      "Gradient : 0.5305477830676235\n",
      "#Iteration : 915000#####\n",
      "Gradient : 0.521123815331982\n",
      "#Iteration : 920000#####\n",
      "Gradient : 0.5118674974702612\n",
      "#Iteration : 925000#####\n",
      "Gradient : 0.5027758259589457\n",
      "#Iteration : 926545#####\n",
      "Gradient : 0.49999933727458373\n",
      "\n",
      "\n",
      "\n",
      "#Learning Rate : 1e-07#####\n",
      "#Iteration : 5000#####\n",
      "Gradient : 6881.519251578328\n",
      "#Iteration : 10000#####\n",
      "Gradient : 4278.6426892919\n",
      "#Iteration : 15000#####\n",
      "Gradient : 2829.331535064353\n",
      "#Iteration : 20000#####\n",
      "Gradient : 2002.1137272080211\n",
      "#Iteration : 25000#####\n",
      "Gradient : 1518.6699626154098\n",
      "#Iteration : 30000#####\n",
      "Gradient : 1223.5977859008256\n",
      "#Iteration : 35000#####\n",
      "Gradient : 1031.1854818305828\n",
      "#Iteration : 40000#####\n",
      "Gradient : 895.9707351369052\n",
      "#Iteration : 45000#####\n",
      "Gradient : 794.407894112654\n",
      "#Iteration : 50000#####\n",
      "Gradient : 714.1569664373735\n",
      "#Iteration : 55000#####\n",
      "Gradient : 648.437909719803\n",
      "#Iteration : 60000#####\n",
      "Gradient : 593.2567115036638\n",
      "#Iteration : 65000#####\n",
      "Gradient : 546.0781399906731\n",
      "#Iteration : 70000#####\n",
      "Gradient : 505.18338682233485\n",
      "#Iteration : 75000#####\n",
      "Gradient : 469.3458495575796\n",
      "#Iteration : 80000#####\n",
      "Gradient : 437.6567022183646\n",
      "#Iteration : 85000#####\n",
      "Gradient : 409.4238648049509\n",
      "#Iteration : 90000#####\n",
      "Gradient : 384.1091913590769\n",
      "#Iteration : 95000#####\n",
      "Gradient : 361.2870552485482\n",
      "#Iteration : 100000#####\n",
      "Gradient : 340.6158163004509\n",
      "#Iteration : 105000#####\n",
      "Gradient : 321.817544971337\n",
      "#Iteration : 110000#####\n",
      "Gradient : 304.66330026257145\n",
      "#Iteration : 115000#####\n",
      "Gradient : 288.96227311004833\n",
      "#Iteration : 120000#####\n",
      "Gradient : 274.55368385149677\n",
      "#Iteration : 125000#####\n",
      "Gradient : 261.30067361657905\n",
      "#Iteration : 130000#####\n",
      "Gradient : 249.08565589765874\n",
      "#Iteration : 135000#####\n",
      "Gradient : 237.8067468649622\n",
      "#Iteration : 140000#####\n",
      "Gradient : 227.37499853938647\n",
      "#Iteration : 145000#####\n",
      "Gradient : 217.7122335624739\n",
      "#Iteration : 150000#####\n",
      "Gradient : 208.74933377805178\n",
      "#Iteration : 155000#####\n",
      "Gradient : 200.4248735118876\n",
      "#Iteration : 160000#####\n",
      "Gradient : 192.68401658856027\n",
      "#Iteration : 165000#####\n",
      "Gradient : 185.47761672424178\n",
      "#Iteration : 170000#####\n",
      "Gradient : 178.76147607161423\n",
      "#Iteration : 175000#####\n",
      "Gradient : 172.49572785911022\n",
      "#Iteration : 180000#####\n",
      "Gradient : 166.64431733271073\n",
      "#Iteration : 185000#####\n",
      "Gradient : 161.1745613499215\n",
      "#Iteration : 190000#####\n",
      "Gradient : 156.05677155437004\n",
      "#Iteration : 195000#####\n",
      "Gradient : 151.26392948655604\n",
      "#Iteration : 200000#####\n",
      "Gradient : 146.77140456141063\n",
      "#Iteration : 205000#####\n",
      "Gradient : 142.55670778667977\n",
      "#Iteration : 210000#####\n",
      "Gradient : 138.5992755699009\n",
      "#Iteration : 215000#####\n",
      "Gradient : 134.88027908522687\n",
      "#Iteration : 220000#####\n",
      "Gradient : 131.38245553308053\n",
      "#Iteration : 225000#####\n",
      "Gradient : 128.08995829124655\n",
      "#Iteration : 230000#####\n",
      "Gradient : 124.9882234740169\n",
      "#Iteration : 235000#####\n",
      "Gradient : 122.06385082286366\n",
      "#Iteration : 240000#####\n",
      "Gradient : 119.3044971747904\n",
      "#Iteration : 245000#####\n",
      "Gradient : 116.6987810131337\n",
      "#Iteration : 250000#####\n",
      "Gradient : 114.23619681529364\n",
      "#Iteration : 255000#####\n",
      "Gradient : 111.90703808400589\n",
      "#Iteration : 260000#####\n",
      "Gradient : 109.70232809162607\n",
      "#Iteration : 265000#####\n",
      "Gradient : 107.61375748706347\n",
      "#Iteration : 270000#####\n",
      "Gradient : 105.6336280169108\n",
      "#Iteration : 275000#####\n",
      "Gradient : 103.75480170001073\n",
      "#Iteration : 280000#####\n",
      "Gradient : 101.97065487044843\n",
      "#Iteration : 285000#####\n",
      "Gradient : 100.27503657018026\n",
      "#Iteration : 290000#####\n",
      "Gradient : 98.66223083055814\n",
      "#Iteration : 295000#####\n",
      "Gradient : 97.12692243333346\n",
      "#Iteration : 300000#####\n",
      "Gradient : 95.66416578704525\n",
      "#Iteration : 305000#####\n",
      "Gradient : 94.26935659508459\n",
      "#Iteration : 310000#####\n",
      "Gradient : 92.93820602748664\n",
      "#Iteration : 315000#####\n",
      "Gradient : 91.66671714045266\n",
      "#Iteration : 320000#####\n",
      "Gradient : 90.45116331595615\n",
      "#Iteration : 325000#####\n",
      "Gradient : 89.28806851905136\n",
      "#Iteration : 330000#####\n",
      "Gradient : 88.17418919299315\n",
      "#Iteration : 335000#####\n",
      "Gradient : 87.1064976321862\n",
      "#Iteration : 340000#####\n",
      "Gradient : 86.0821666907077\n",
      "#Iteration : 345000#####\n",
      "Gradient : 85.0985556998334\n",
      "#Iteration : 350000#####\n",
      "Gradient : 84.15319748189553\n",
      "#Iteration : 355000#####\n",
      "Gradient : 83.24378636007634\n",
      "#Iteration : 360000#####\n",
      "Gradient : 82.36816707457227\n",
      "#Iteration : 365000#####\n",
      "Gradient : 81.52432452520233\n",
      "#Iteration : 370000#####\n",
      "Gradient : 80.71037426890648\n",
      "#Iteration : 375000#####\n",
      "Gradient : 79.92455370809141\n",
      "#Iteration : 380000#####\n",
      "Gradient : 79.16521391230754\n",
      "#Iteration : 385000#####\n",
      "Gradient : 78.43081202157262\n",
      "#Iteration : 390000#####\n",
      "Gradient : 77.71990418471843\n",
      "#Iteration : 395000#####\n",
      "Gradient : 77.03113899071015\n",
      "#Iteration : 400000#####\n",
      "Gradient : 76.36325135480959\n",
      "#Iteration : 405000#####\n",
      "Gradient : 75.71505682504032\n",
      "#Iteration : 410000#####\n",
      "Gradient : 75.08544627750189\n",
      "#Iteration : 415000#####\n",
      "Gradient : 74.47338097188253\n",
      "#Iteration : 420000#####\n",
      "Gradient : 73.87788794098651\n",
      "#Iteration : 425000#####\n",
      "Gradient : 73.29805569029409\n",
      "#Iteration : 430000#####\n",
      "Gradient : 72.73303018556199\n",
      "#Iteration : 435000#####\n",
      "Gradient : 72.18201110823705\n",
      "#Iteration : 440000#####\n",
      "Gradient : 71.64424836004541\n",
      "#Iteration : 445000#####\n",
      "Gradient : 71.11903879957558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration : 450000#####\n",
      "Gradient : 70.60572319495868\n",
      "#Iteration : 455000#####\n",
      "Gradient : 70.10368337794408\n",
      "#Iteration : 460000#####\n",
      "Gradient : 69.61233958574664\n",
      "#Iteration : 465000#####\n",
      "Gradient : 69.13114797800819\n",
      "#Iteration : 470000#####\n",
      "Gradient : 68.65959831714709\n",
      "#Iteration : 475000#####\n",
      "Gradient : 68.19721180115397\n",
      "#Iteration : 480000#####\n",
      "Gradient : 67.74353903869631\n",
      "#Iteration : 485000#####\n",
      "Gradient : 67.2981581570552\n",
      "#Iteration : 490000#####\n",
      "Gradient : 66.86067303409098\n",
      "#Iteration : 495000#####\n",
      "Gradient : 66.43071164601697\n",
      "#Iteration : 500000#####\n",
      "Gradient : 66.00792452332463\n",
      "#Iteration : 505000#####\n",
      "Gradient : 65.59198330770849\n"
     ]
    }
   ],
   "source": [
    "weights1, sse1, gradient1, iter1 = linear_regress(x_norm, y, 10**0,  200000, 0)\n",
    "weights2, sse2, gradient2, iter2 = linear_regress(x_norm, y, 10**-1, 200000, 0)\n",
    "weights3, sse3, gradient3, iter3 = linear_regress(x_norm, y, 10**-2, 200000, 0)\n",
    "weights4, sse4, gradient4, iter4 = linear_regress(x_norm, y, 10**-3, 200000, 0)\n",
    "weights5, sse5, gradient5, iter5 = linear_regress(x_norm, y, 10**-4, 200000, 0)\n",
    "weights6, sse6, gradient6, iter6 = linear_regress(x_norm, y, 10**-5, 500000, 0)\n",
    "weights7, sse7, gradient7, iter7 = linear_regress(x_norm, y, 10**-6, 5000000, 0)\n",
    "weights8, sse8, gradient8, iter8 = linear_regress(x_norm, y, 10**-7, 50000000, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[417729.13677477534,\n",
       " 1441711259931547.5,\n",
       " 6.794374698184466e+24,\n",
       " 3.202181295174746e+34,\n",
       " 1.5091845552447712e+44,\n",
       " 7.112770364740612e+53,\n",
       " 3.352240922803048e+63,\n",
       " 1.579907494303781e+73]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'SSE')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sse)\n",
    "plt.legend(['1e-0'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
