{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSVs\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get training, validation and test data\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(\"./PA1_train.csv\")\n",
    "    dev = pd.read_csv(\"./PA1_dev.csv\")\n",
    "    test = pd.read_csv(\"./PA1_test.csv\")\n",
    "    return train,dev,test\n",
    "\n",
    "#Add bias\n",
    "def add_bias(df):\n",
    "    \"\"\"\n",
    "    Add dummy variable to control intercept\n",
    "    \"\"\"\n",
    "    df[\"dummy\"] = 1\n",
    "    return df\n",
    "\n",
    "#Seperate Features from response\n",
    "def seperate(df_train):\n",
    "    \"\"\"\n",
    "    input: dataframe\n",
    "    \"\"\"\n",
    "    #Grab all continuous features\n",
    "    x = df_train.iloc[:,0:-1]\n",
    "    #Split dates\n",
    "    x = split_date(x)\n",
    "    x = x.drop([\"date\"], axis=1)\n",
    "    #Grab response y\n",
    "    y = df_train.iloc[:,-1]\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "    \n",
    "#Add new features [Month, Day, Year]\n",
    "def split_date(df_train):\n",
    "    \"\"\"\n",
    "    splits date into seperate features\n",
    "    input: dataframe\n",
    "    \"\"\"\n",
    "    print(\"Splitting date...\")\n",
    "    for i in range(0,len(df_train)):\n",
    "        df_train.loc[i,\"month\"] = int(df_train.loc[i,\"date\"].split(\"/\")[0])\n",
    "        df_train.loc[i,\"day\"] = int(df_train.loc[i,\"date\"].split(\"/\")[1])\n",
    "        df_train.loc[i,\"year\"] = int(df_train.loc[i,\"date\"].split(\"/\")[2])\n",
    "    print(\"Done\")\n",
    "    return df_train\n",
    "\n",
    "#Normalize data\n",
    "def normalize(df1):\n",
    "    \"\"\"\n",
    "    Normalizes feature matrix\n",
    "    input: feature df\n",
    "    \"\"\"\n",
    "    print(\"Normalizing...\")\n",
    "    x = (df1 - np.min(df1))/(np.max(df1) - np.min(df1))\n",
    "    print(\"DONE\")\n",
    "    return x\n",
    "\n",
    "#Linear regression function\n",
    "def linear_regress(x,y,eta,t,lamb):\n",
    "    \"\"\"\n",
    "    x: input/features\n",
    "    y: opuput\n",
    "    eta: learning rate\n",
    "    t: iterations\n",
    "    lamb: regularization constant\n",
    "    \"\"\"\n",
    "    print(f'#Learning Rate : {eta}#####')\n",
    "    \n",
    "    n = 0\n",
    "    e = np.zeros(len(y))\n",
    "    errors = []\n",
    "    gradient = []\n",
    "    \n",
    "    #Initialize weights [w] and predictions [y_hat]\n",
    "    w = np.zeros(len(x[0]))\n",
    "    \n",
    "     \n",
    "    while n<t:\n",
    "        #Initialize gradient for each epoch\n",
    "        gradient_vector = np.zeros(len(x[0]))\n",
    "                \n",
    "        #Traverse through each data point   \n",
    "        for i in range(len(x)):\n",
    "            #Predicted value\n",
    "            y_hat = np.dot(w.T,x[i])\n",
    "\n",
    "            #Error\n",
    "            e[i] = ((y[i] - y_hat)**2)\n",
    "            \n",
    "            \n",
    "            #Regularization\n",
    "            if np.dot(w.T,w) == 0:\n",
    "                r = 0\n",
    "            else:\n",
    "                r = (np.dot(w.T,w))**0.5\n",
    "            \n",
    "            #Traverse through each feature to update corresponding weights\n",
    "            for j in range(len(x[0])):\n",
    "                gradient_vector[j] += ((-2)*(y[i] - y_hat)*x[i,j]) + (2*lamb*r)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Update weights\n",
    "        w -=  eta*gradient_vector\n",
    "        #Calculate SSE\n",
    "        errors.append(sum(e))\n",
    "        #Norm of gradient\n",
    "        convergence_criteria = np.dot(gradient_vector.T,gradient_vector)**0.5\n",
    "        gradient.append(convergence_criteria)\n",
    "        \n",
    "        ####\n",
    "        #print(f'#####Iteration : {n+1}#####')\n",
    "        #print(f'Gradient : {gradient[n]}')\n",
    "\n",
    "        \n",
    "        ####\n",
    "        if (gradient[n]/(10**9)) > 1 and (n+1) <= 6:\n",
    "            t = 8\n",
    "        \n",
    "        n += 1\n",
    "        if convergence_criteria < 0.5:\n",
    "            print(f'#Iteration : {n}#####')\n",
    "            print(f'Gradient : {gradient[n-1]}')\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            return w,errors,gradient, n\n",
    "        if (n) % 50 == 0:\n",
    "            print(f'#Iteration : {n}#####')\n",
    "            print(f'Gradient : {gradient[n-1]}')\n",
    "\n",
    "    print(f'#Iteration : {n}#####')\n",
    "    print(f'Gradient : {gradient[n-1]}')\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    return w,errors,gradient, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting date...\n",
      "Done\n",
      "Normalizing...\n",
      "DONE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.246849</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368687</td>\n",
       "      <td>0.761782</td>\n",
       "      <td>0.394979</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.234244</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631313</td>\n",
       "      <td>0.683127</td>\n",
       "      <td>0.112971</td>\n",
       "      <td>0.318584</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.707093</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.226549</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.141807</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.515522</td>\n",
       "      <td>0.300418</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.363445</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.690043</td>\n",
       "      <td>0.335565</td>\n",
       "      <td>0.361062</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.231092</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.526621</td>\n",
       "      <td>0.298745</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.007566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843434</td>\n",
       "      <td>0.540454</td>\n",
       "      <td>0.169874</td>\n",
       "      <td>0.138053</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.122899</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.966061</td>\n",
       "      <td>0.158159</td>\n",
       "      <td>0.304425</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.145607</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.192227</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297089</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.327434</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dummy  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0         1   0.09375   0.275862     0.246849  0.005715     0.4         0.0   \n",
       "1         1   0.03125   0.275862     0.234244  0.002682     0.0         0.0   \n",
       "2         1   0.12500   0.172414     0.134454  0.001471     0.2         0.0   \n",
       "3         1   0.09375   0.172414     0.141807  0.005469     0.0         0.0   \n",
       "4         1   0.15625   0.241379     0.363445  0.006426     0.0         0.0   \n",
       "...     ...       ...        ...          ...       ...     ...         ...   \n",
       "9995      1   0.09375   0.275862     0.231092  0.013111     0.4         0.0   \n",
       "9996      1   0.00000   0.068966     0.044118  0.007566     0.0         0.0   \n",
       "9997      1   0.06250   0.137931     0.122899  0.004200     0.0         0.0   \n",
       "9998      1   0.06250   0.241379     0.157563  0.000804     0.8         0.0   \n",
       "9999      1   0.09375   0.275862     0.192227  0.005346     0.4         0.0   \n",
       "\n",
       "      view  condition     grade  ...  yr_built  yr_renovated   zipcode  \\\n",
       "0      0.0       0.50  0.555556  ...  0.773913           0.0  0.368687   \n",
       "1      0.0       1.00  0.444444  ...  0.226087           0.0  0.631313   \n",
       "2      0.0       0.50  0.444444  ...  0.017391           0.0  0.722222   \n",
       "3      0.0       0.75  0.444444  ...  0.600000           0.0  0.292929   \n",
       "4      0.5       1.00  0.555556  ...  0.539130           0.0  0.035354   \n",
       "...    ...        ...       ...  ...       ...           ...       ...   \n",
       "9995   0.0       1.00  0.333333  ...  0.504348           0.0  0.292929   \n",
       "9996   0.0       0.50  0.222222  ...  0.365217           0.0  0.843434   \n",
       "9997   0.0       1.00  0.333333  ...  0.530435           0.0  0.777778   \n",
       "9998   0.0       0.50  0.444444  ...  0.939130           0.0  0.515152   \n",
       "9999   0.0       0.50  0.444444  ...  0.756522           0.0  0.000000   \n",
       "\n",
       "           lat      long  sqft_living15  sqft_lot15     month       day  year  \n",
       "0     0.761782  0.394979       0.400000    0.011601  0.545455  0.266667   0.0  \n",
       "1     0.683127  0.112971       0.318584    0.004985  0.545455  0.566667   0.0  \n",
       "2     0.707093  0.174059       0.226549    0.003837  0.545455  0.200000   0.0  \n",
       "3     0.515522  0.300418       0.212389    0.011556  0.272727  0.900000   1.0  \n",
       "4     0.690043  0.335565       0.361062    0.011188  0.727273  0.100000   0.0  \n",
       "...        ...       ...            ...         ...       ...       ...   ...  \n",
       "9995  0.526621  0.298745       0.353982    0.006746  0.727273  0.833333   0.0  \n",
       "9996  0.540454  0.169874       0.138053    0.007440  0.454545  0.100000   0.0  \n",
       "9997  0.966061  0.158159       0.304425    0.008033  0.181818  0.533333   1.0  \n",
       "9998  0.800708  0.145607       0.217699    0.001188  0.909091  0.566667   0.0  \n",
       "9999  0.297089  0.205021       0.327434    0.009782  0.363636  0.033333   0.0  \n",
       "\n",
       "[10000 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####DATA PREP#####\n",
    "\n",
    "#load csv\n",
    "df_train,df_dev,df_test = get_data()\n",
    "#Drop ID Feature\n",
    "df_train = df_train.drop(\"id\", axis=1)\n",
    "\n",
    "#Grab features and Response\n",
    "x,y = seperate(df_train)\n",
    "\n",
    "#Normalize continuous features\n",
    "x_norm_df = normalize(x)\n",
    "#Add Bias \n",
    "x_norm_df = add_bias(x_norm_df)\n",
    "x_norm = x_norm_df.values\n",
    "\n",
    "x_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Learning Rate : 1#####\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-fa99e5ba6135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mweights2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweights3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mweights4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mweights5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-478add3f3751>\u001b[0m in \u001b[0;36mlinear_regress\u001b[1;34m(x, y, eta, t, lamb)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m#Traverse through each feature to update corresponding weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights1, sse1, gradient1, iter1 = linear_regress(x_norm, y, 10**0, 50000, 0)\n",
    "weights2, sse2, gradient2, iter2 = linear_regress(x_norm, y, 10**-1, 50000, 0)\n",
    "weights3, sse3, gradient3, iter3 = linear_regress(x_norm, y, 10**-2, 50000, 0)\n",
    "weights4, sse4, gradient4, iter4 = linear_regress(x_norm, y, 10**-3, 50000, 0)\n",
    "weights5, sse5, gradient5, iter5 = linear_regress(x_norm, y, 10**-4, 50000, 0)\n",
    "weights6, sse6, gradient6, iter6 = linear_regress(x_norm, y, 10**-5, 50000, 0)\n",
    "weights7, sse7, gradient7, iter7 = linear_regress(x_norm, y, 10**-6, 50000, 0)\n",
    "weights8, sse8, gradient8, iter8 = linear_regress(x_norm, y, 10**-7, 50000, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[417729.13677477534,\n",
       " 1441711259931547.5,\n",
       " 6.794374698184466e+24,\n",
       " 3.202181295174746e+34,\n",
       " 1.5091845552447712e+44,\n",
       " 7.112770364740612e+53,\n",
       " 3.352240922803048e+63,\n",
       " 1.579907494303781e+73]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'SSE')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAf90lEQVR4nO3deZRc5X3m8e+j1r60BFKLSOrWYkuABUZItLEZJzaJnYxwMiKbxyhxGGI7SoixkzjLkEwGJ2RyjhPPTOycOHZkYAgJFrFNghUfAp7ECx4TMKJLEkiyQMiouiRAjajSipbu/s0fdUuUm251S+rbt5bnc04f6tZ969YPDqefvu973/dVRGBmZs1rXNYFmJlZthwEZmZNzkFgZtbkHARmZk3OQWBm1uQcBGZmTa4ug0DSXZL2S3p6BG1vktQjaXPy86Gqc38m6enk533pVm1mVpvqMgiAu4HVZ9H+HyLiyuTnDgBJPwmsAq4E3gr8rqTWUa/UzKzG1WUQRMQjwCvV70l6o6SHJD0p6duSLh3mMsuBb0VEb0QcBbZwduFiZtYQ6jIIhrAe+EhEXAX8DvDXVed+TtJWSV+W1JG8twW4TtJUSXOAHwU6MDNrMuOzLmA0SJoO/AfgS5Iqb09K/vnPwIaIOCHp14C/BX4sIr4m6S3Ao0AP8O9A79hWbmaWPdXrWkOSFgNfjYjLk779nRExb5jPtACvRMTMQc59Afj7iHgwjXrNzGpVQ3QNRcQh4PuS3gugshXJ6+pwWAPsSN5vkTQ7eX0FcAXwtTEt3MysBtRl15CkDcC1wBxJBeDjwC8Cn5X0h8AE4D7K4wAflbSGcrfPK8BNyWUmAN9OupIOAe+PCHcNmVnTqduuITMzGx0N0TVkZmbnru66hubMmROLFy/Ougwzs7ry5JNPvhwRbYOdq7sgWLx4MZs2bcq6DDOzuiJpz1Dn3DVkZtbkHARmZk0utSAYyQqhkq5NVgTdJulbadViZmZDS3OM4G7gr4B7BjspaRbl9YBWR0Re0txz/aJTp05RKBQ4fvz4uV6iLkyePJn29nYmTJiQdSlm1kBSC4KIeCRZBmIovwD8Y0Tkk/b7z/W7CoUCM2bMYPHixVStNdRQIoIDBw5QKBRYsmRJ1uWYWQPJcozgYuACSd9Mlo6+caiGktZJ2iRpU09Pz+vOHz9+nNmzZzdsCABIYvbs2Q1/12NmYy/LIBgPXAX8JPAfgf8u6eLBGkbE+ojojIjOtrZBH4Nt6BCoaIZ/RzMbe1kGQQF4KCKORsTLwCPAigzrMTOrWZ/+12f5zq6XU7l2lkHwFeBHJI2XNJXydpE7MqznvHzgAx9g7ty5XH755Wf92SeffJI3v/nNLF26lI9+9KN4/Sczq3b4+Ck+9W/PsOn5YirXT/Px0Q2UN3u5RFJB0gcl/VqyOQwRsQN4CNgKfBe4IyKG3Yy+Vt1000089NBD5/TZm2++mfXr1/Pss8/y7LPPnvN1zKwxbek+SASsXDgrleun+dTQ2hG0+STwybRqGEvveMc7eP7553/gveeee44Pf/jD9PT0MHXqVD7/+c9z6aU/uJXyCy+8wKFDh7jmmmsAuPHGG3nggQe47rrrxqp0M6txuXwRCa6styDIyh//8za27zs0qtdcPr+Vj/+ny876c+vWreNzn/scy5Yt4/HHH+fXf/3X+frXv/4Dbfbu3Ut7e/vp4/b2dvbu3XveNZtZ48h1l1jaNp3WyenMIWq4IKgVR44c4dFHH+W9733v6fdOnDjxunaDjQf46SAzq4gIcvkiP778otS+o+GC4Fz+ck9Df38/s2bNYvPmzT/wfl9fH1dddRUAa9as4eabb6ZQKJw+XygUmD9//pjWama16/kDxygeO8WqhRek9h1edC4lra2tLFmyhC996UtAOdW3bNlCS0sLmzdvZvPmzdx+++3MmzePGTNm8NhjjxER3HPPPVx//fUZV29mtSKXLz8ptNJBUPvWrl3LNddcw86dO2lvb+fOO+/k3nvv5c4772TFihVcdtllfOUrXxn0s5/97Gf50Ic+xNKlS3njG9/ogWIzOy2XLzF90niWzp2e2nc0XNdQVjZs2DDo+yN5FLSzs5Onn67bJ2fNLEVd+SIrOmbSMi69sUPfEZiZ1ahjJ3v53ouHUx0fAAeBmVnNeqpwkL7+SG0iWUXDBEEzLMvQDP+OZvaarnwJgCs7fEcwrMmTJ3PgwIGG/kVZ2Y9g8uTJWZdiZmMkly+yZM40Lpw2MdXvaYjB4vb2dgqFAoPtVdBIKjuUmVnjiwhy3SV+ZOmc1L+rIYJgwoQJ3rXLzBpKofgqPYdPpD4+AA3SNWRm1mhy3eXxgTQnklU4CMzMalAuX2TyhHFc+kMzUv8uB4GZWQ3qype4on0W41vS/zXtIDAzqzHHT/Wxfd/B1CeSVaS5Q9ldkvZLOuPaCZLeIqlP0s+nVYuZWT3Ztu8Qp/rSn0hWkeYdwd3A6jM1kNQC/BnwcIp1mJnVldMrjnbUeRBExCPAK8M0+whwP7A/rTrMzOpNLl9iwawpzG0dmwmkmY0RSFoA/AzwuRG0XSdpk6RNjT5pzMwsly+yatHYjA9AtoPFnwL+a0T0DdcwItZHRGdEdLa1tY1BaWZm2Xjx4HH2HTw+Zt1CkO3M4k7gvmR/3jnAeyT1RsQDGdZkZpap13Yka4IgiIjTa0JIuhv4qkPAzJpdrrvExPHjuGz+zDH7ztSCQNIG4FpgjqQC8HFgAkBEDDsuYGbWjHL5IpfPb2Xi+LHruU8tCCJi7Vm0vSmtOszM6sXJ3n62Fg7y/rctGtPv9cxiM7Ma8b0XD3Git3/MZhRXOAjMzGpELl9ZcXTsBorBQWBmVjO68kUuap3EvJljuxOhg8DMrEbk8iVWLbyA5LH6MeMgMDOrAS8fOUH+lWNj3i0EDgIzs5rw2vjA2A4Ug4PAzKwm5PJFxo8Tb14wdhPJKhwEZmY1IJcvsXx+K5MntIz5dzsIzMwy1tcfbCmUxnShuWoOAjOzjO188TDHTvZlMj4ADgIzs8zlussrjo71jOIKB4GZWcZy+RKzp02k48IpmXy/g8DMLGNd+SIrF84a84lkFQ4CM7MMlY6dZHfP0czGB8BBYGaWqc3d2Sw0V81BYGaWoa58iXGCFe0NGASS7pK0X9LTQ5z/RUlbk59HJa1IqxYzs1qVyxe55IdamTYpuy3k07wjuBtYfYbz3wfeGRFXAH8CrE+xFjOzmtPfH2zuLmXaLQTpblX5iKTFZzj/aNXhY0B7WrWYmdWi53qOcPh4b2YziitqZYzgg8C/ZF2EmdlYynLF0WrZdUolJP0o5SD44TO0WQesA1i4cOEYVWZmlq5cd5GZUybwhjnTMq0j0zsCSVcAdwDXR8SBodpFxPqI6IyIzra2trEr0MwsRV17SlzZMYtx47KZSFaRWRBIWgj8I/BLEfFMVnWYmWXh8PFTPLP/cOYDxZBi15CkDcC1wBxJBeDjwASAiPgccBswG/jrZFp1b0R0plWPmVkt2Vo4SER2C81VS/OpobXDnP8Q8KG0vt/MrJbl8uUVR1dk/MQQ1M5TQ2ZmTaUrX2Lp3OnMnDIh61IcBGZmYy0iyOWLrKqB8QFwEJiZjbk9B45RPHYq8/kDFQ4CM7Mx1pWMD9TCE0PgIDAzG3O5fInpk8azbO6MrEsBHARmZmMu111kRcdMWjKeSFbhIDAzG0PHTvay44XDrOyojfEBcBCYmY2ppwoH6euPmhkfAAeBmdmYynXXxoqj1RwEZmZjqGtPkcWzp3LhtIlZl3Kag8DMbIxEBLnuUk3dDYCDwMxszOwtvUrP4RM1M6O4wkFgZjZGamVHsoEcBGZmY6QrX2TyhHFc8kO1MZGswkFgZjZGcvkSV7TPYkJLbf3qra1qzMwa1InePrbvO1RT8wcqUgsCSXdJ2i/p6SHOS9JfStolaaukVWnVYmaWtaf3HuJkX39NzSiuSPOO4G5g9RnOXwcsS37WAZ9NsRYzs0xVdiSrtSeGIMUgiIhHgFfO0OR64J4oewyYJWleWvWYmWUp111iwawpzG2dnHUpr5PlGMECoLvquJC8Z2bWcHJ7ijU5PgDZBsFg66/GoA2ldZI2SdrU09OTcllmZqPrxYPH2XfwOKtqbP5ARZZBUAA6qo7bgX2DNYyI9RHRGRGdbW1tY1Kcmdlo2dxdWzuSDZRlEGwEbkyeHnobcDAiXsiwHjOzVHTlS0xsGcfy+a1ZlzKo8WldWNIG4FpgjqQC8HFgAkBEfA54EHgPsAs4BvxyWrWYmWUply9y2YJWJo1vybqUQaUWBBGxdpjzAXw4re83M6sFp/r62Vo4yPvftijrUobkmcVmZin63guHOdHbX7PjA+AgMDNLVVe+MlBcm08MgYPAzCxVuXyRi1onMX9m7U0kq3AQmJmlKNddYmXHBUiDTZ2qDQ4CM7OUvHzkBHsOHKvp8QFwEJiZpWZzsiPZqkW1Oz4ADgIzs9TkuouMHycunz8z61LOyEFgZpaSrj0l3jSvlSkTa3MiWYWDwMwsBX39wZZCqSb3HxjIQWBmloJnXjrMsZN9NT1/oMJBYGaWgtcmkvmOwMysKeXyJS6cNpGFF07NupRhOQjMzFKQyxdZtXBWTU8kq3AQmJmNstKxkzzXc7QuxgdgmCCQNOQuCpIWjn45Zmb1b3N3eSLZyo7aHx+A4e8Ivll5IenfBpx7YNSrMTNrALl8iXGCKxokCKo7ty48w7nBPyytlrRT0i5Jtw5yfqGkb0jKSdoq6T0jqNnMrKbluktcfNEMpk9Kbe+vUTVcEMQQrwc7/gGSWoDPANcBy4G1kpYPaPaHwBcjYiVwA/DXw1ZsZlbD+vuDXL5YN+MDMPxWlXMlfYzyX/+V1yTHbcN89mpgV0TsBpB0H3A9sL2qTQCVcYiZwL6zqN3MrObsfvkIh4/31sWM4orhguDzwIxBXgPcMcxnFwDdVccF4K0D2vwR8DVJHwGmAe8e5ppmZjWtK1lxtGHuCCLij8/j2oONIQzsTloL3B0R/0vSNcDfSbo8Ivp/4ELSOmAdwMKFfljJzGpXLl+kdfJ43jBnWtaljNhwj4/+iqRlyWtJukvSwWRgd+Uw1y4AHVXH7by+6+eDwBcBIuLfgcnAnIEXioj1EdEZEZ1tbcP1SJmZZSeXL7Fy4QWMG1f7E8kqhhss/g3g+eT1WmAF8AbgY8BfDvPZJ4BlkpZImkh5MHjjgDZ54F0Akt5EOQh6Rlq8mVktOXKil50vHa6L9YWqDRcEvRFxKnn9U8A9EXEgIv6Vcp/+kCKiF7gFeBjYQfnpoG2Sbpe0Jmn228CvSNoCbABuiogzPo1kZlartnSXiKiv8QEYfrC4X9I8oEj5L/c/rTo3ZbiLR8SDwIMD3rut6vV24O0jrtbMrIblkhVHr2yvrzuC4YLgNmAT0AJsjIhtAJLeCexOuTYzs7qSy5dYOnc6M6dOyLqUszJcELwEXAMcjoiipBuBn0veX5d2cWZm9SIiyHWXeNelc7Mu5awNN0bwN8CRJATeAXwCuIdyEHw67eLMzOrFngPHeOXoybobH4Dh7whaIuKV5PX7gPURcT9wv6TN6ZZmZlY/ct3l8YFVi+prfACGvyNokVQJi3cBX686Vx+rKZmZjYFcvsS0iS0smztj+MY1Zrhf5huAb0l6GXgV+DaApKXAwZRrMzOrG135Iis6ZtFSRxPJKs54RxARf0r5Wf+7gR+uesZ/HPCRdEszM6sPr57sY8cLh1lVh+MDMILunYh4bJD3nkmnHDOz+vPU3oP09UfdzSiu8J7FZmbnqasykaxOdiQbyEFgZnaecvkii2dPZfb0SVmXck4cBGZm5yEi6EpWHK1XDgIzs/Owt/QqPYdP1O34ADgIzMzOS66yI1mH7wjMzJpSLl9i8oRxXDqv/iaSVTgIzMzOQ1e+yBULZjGhpX5/ndZv5WZmGTvR28f2fYfqenwAHARmZuds275DnOzrr+snhiDlIJC0WtJOSbsk3TpEm/8sabukbZK+kGY9Zmaj6fRAcZ3fEaS2gqikFuAzwI8DBeAJSRuT7SkrbZYBvw+8PdnzoP52dDCzptWVL7Jg1hQuap2cdSnnJc07gquBXRGxOyJOAvcB1w9o8yvAZyKiCBAR+1Osx8xsVG3Ol+r+bgDSDYIFQHfVcSF5r9rFwMWSviPpMUmrB7uQpHWSNkna1NPTk1K5ZmYj99Kh4+wtvVr34wOQbhAMtih3DDgeDywDrgXWAndIel28RsT6iOiMiM62trZRL9TM7GzlkoXmfEdwZgWgo+q4Hdg3SJuvRMSpiPg+sJNyMJiZ1bRcvsTElnFcNr8161LOW5pB8ASwTNISSROBG4CNA9o8APwogKQ5lLuKdqdYk5nZqMjlS1y2oJVJ41uyLuW8pRYEEdEL3AI8DOwAvhgR2yTdLmlN0uxh4ICk7cA3gN+NiANp1WRmNhpO9fWzdW+prtcXqpbqBvQR8SDw4ID3bqt6HcDHkh8zs7rwvRcOc/xUf0OMD4BnFpuZnbVcd3mgeNWixrgjcBCYmZ2lrj1F5s6YxPyZ9T2RrMJBYGZ2lnLd5Ylk0mBPydcfB4GZ2Vk4cOQEew4cY1UDTCSrcBCYmZ2F1xaacxCYmTWlXHeR8ePEmxfMzLqUUeMgMDM7C7l8iTfNa2XKxPqfSFbhIDAzG6G+/mBLd2OsOFrNQWBmNkLPvHSYoyf7HARmZs2qMlDcSE8MgYPAzGzEcvkiF06byMILp2ZdyqhyEJiZjVBXvsjKjsaZSFbhIDAzG4GDx07xXM/RhllfqJqDwMxsBDYXkolkHY01UAwOAjOzEenaU0SCKxwEZmbNKddd4pKLZjB9UqrbuGQi1SCQtFrSTkm7JN16hnY/LykkdaZZj5nZuejvDzbniw21vlC11IJAUgvwGeA6YDmwVtLyQdrNAD4KPJ5WLWZm52P3y0c4dLy34SaSVaR5R3A1sCsidkfESeA+4PpB2v0J8OfA8RRrMTM7Z12nJ5I5CM7WAqC76riQvHeapJVAR0R89UwXkrRO0iZJm3p6eka/UjOzM8jlS7ROHs8b5kzPupRUpBkEg824iNMnpXHAXwC/PdyFImJ9RHRGRGdbW9solmhmNrxcvsiVCy9g3LjGmkhWkWYQFICOquN2YF/V8QzgcuCbkp4H3gZs9ICxmdWSIyd6eealww05f6AizSB4AlgmaYmkicANwMbKyYg4GBFzImJxRCwGHgPWRMSmFGsyMzsrW7tL9AcNOaO4IrUgiIhe4BbgYWAH8MWI2Cbpdklr0vpeM7PRlOsuDxRf2d64dwSpzoyIiAeBBwe8d9sQba9NsxYzs3PRtafIG9umMXPqhKxLSY1nFpuZDSEiyHWXGm7/gYEcBGZmQ8i/coxXjp5s2BnFFQ4CM7MhdOWLAA07o7jCQWBmNoRcvsS0iS1cfNGMrEtJlYPAzGwIuXyJFR2zaGnQiWQVDgIzs0G8erKPHS8cavhuIXAQmJkN6qm9B+ntD1Z2NPZAMTgIzMwGlWuSgWJwEJiZDaorX2TR7KnMnj4p61JS5yAwMxsgIujKlxp6oblqDgIzswH2HTxOz+ETDb3QXDUHgZnZAKfHB5pgoBgcBGZmr9O1p8TkCeO4dF5jTySrcBCYmQ2Q6y5yxYJZTGhpjl+RzfFvaWY2Qid6+9i2tzkmklU4CMzMqmzbd4iTff0OgtEiabWknZJ2Sbp1kPMfk7Rd0lZJ/yZpUZr1mJkNJ5cv70jW6EtPV0stCCS1AJ8BrgOWA2slLR/QLAd0RsQVwJeBP0+rHjOzkcjliyyYNYWLWidnXcqYSfOO4GpgV0TsjoiTwH3A9dUNIuIbEXEsOXwMaE+xHjOzYeXyJa5som4hSDcIFgDdVceF5L2hfBD4l8FOSFonaZOkTT09PaNYopnZa146dJy9pVebZkZxRZpBMNgC3jFoQ+n9QCfwycHOR8T6iOiMiM62trZRLNHM7DWV8YFmmVFcMT7FaxeAjqrjdmDfwEaS3g38N+CdEXEixXrMzM4oly8ysWUcl81vzbqUMZXmHcETwDJJSyRNBG4ANlY3kLQS+BtgTUTsT7EWM7Nh5fIlls9vZdL4lqxLGVOpBUFE9AK3AA8DO4AvRsQ2SbdLWpM0+yQwHfiSpM2SNg5xOTOzVJ3q62fr3hKrmuix0Yo0u4aIiAeBBwe8d1vV63en+f1mZiO188XDHD/VXBPJKjyz2MyM8kY00Bw7kg3kIDAzozw+MHfGJBbMmpJ1KWPOQWBmRvmJoZULZyEN9uR7Y3MQmFnTO3DkBM8fONZU6wtVcxCYWdPb3J0sNNdkM4orHARm1vRy+RIt48QV7Q4CM7Om1JUv8qZ5M5gysbkmklU4CMysqfX1B1u6S02zUf1gHARm1tSe3X+Yoyf7WLWoObuFwEFgZk2ua09loNh3BGZmTSmXL3LhtIksmj0161Iy4yAws6aW6y6xsqM5J5JVOAjMrGkdfPUUu/Yfacr1hao5CMysaZ2eSNakM4orHARm1rRy+SISrGjSGcUVDgIza1q5fIlLLprB9Empbs1S81INAkmrJe2UtEvSrYOcnyTpH5Lzj0tanGY9ZmYV/f1xesXRZpdaEEhqAT4DXAcsB9ZKWj6g2QeBYkQsBf4C+LO06jEzq7b75aMcOt7b1PMHKtK8H7oa2BURuwEk3QdcD2yvanM98EfJ6y8DfyVJERGjXcy3nunhf3x1+/ANzawpHD3RC9DUM4or0gyCBUB31XEBeOtQbSKiV9JBYDbwcnUjSeuAdQALFy48p2KmTxrPsoumn9NnzawxvWfmFN4wx78X0gyCwWZnDPxLfyRtiIj1wHqAzs7Oc7pbuGrRBVy16Kpz+aiZWUNLc7C4AHRUHbcD+4ZqI2k8MBN4JcWazMxsgDSD4AlgmaQlkiYCNwAbB7TZCPyX5PXPA19PY3zAzMyGllrXUNLnfwvwMNAC3BUR2yTdDmyKiI3AncDfSdpF+U7ghrTqMTOzwaU6iyIiHgQeHPDebVWvjwPvTbMGMzM7M88sNjNrcg4CM7Mm5yAwM2tyDgIzsyanentaU1IPsOccPz6HAbOWa1w91VtPtUJ91VtPtUJ91VtPtcL51bsoItoGO1F3QXA+JG2KiM6s6xipeqq3nmqF+qq3nmqF+qq3nmqF9Op115CZWZNzEJiZNblmC4L1WRdwluqp3nqqFeqr3nqqFeqr3nqqFVKqt6nGCMzM7PWa7Y7AzMwGcBCYmTW5pgkCSasl7ZS0S9KtWddzJpLukrRf0tNZ1zIcSR2SviFph6Rtkn4j65qGImmypO9K2pLU+sdZ1zQSklok5SR9NetazkTS85KekrRZ0qas6xmOpFmSvizpe8n/v9dkXdNgJF2S/Det/ByS9Juj+h3NMEYgqQV4BvhxypvhPAGsjYia3MRY0juAI8A9EXF51vWciaR5wLyI6JI0A3gS+Ola/G8rScC0iDgiaQLw/4DfiIjHMi7tjCR9DOgEWiPip7KuZyiSngc6I6IuJmhJ+lvg2xFxR7JnytSIKGVd15kkv8v2Am+NiHOdWPs6zXJHcDWwKyJ2R8RJ4D7g+oxrGlJEPEKd7NQWES9ERFfy+jCwg/Je1DUnyo4khxOSn5r+S0hSO/CTwB1Z19JIJLUC76C8JwoRcbLWQyDxLuC50QwBaJ4gWAB0Vx0XqNFfVvVM0mJgJfB4tpUMLelm2QzsB/5vRNRsrYlPAb8H9GddyAgE8DVJT0pal3Uxw3gD0AP8n6Tb7Q5J07IuagRuADaM9kWbJQg0yHs1/ZdgvZE0Hbgf+M2IOJR1PUOJiL6IuJLyHtpXS6rZrjdJPwXsj4gns65lhN4eEauA64APJ12ctWo8sAr4bESsBI4CtT52OBFYA3xptK/dLEFQADqqjtuBfRnV0nCS/vb7gXsj4h+zrmckkm6AbwKrMy7lTN4OrEn63u8DfkzS32db0tAiYl/yz/3AP1Hukq1VBaBQdUf4ZcrBUMuuA7oi4qXRvnCzBMETwDJJS5JUvQHYmHFNDSEZgL0T2BER/zvres5EUpukWcnrKcC7ge9lW9XQIuL3I6I9IhZT/n/26xHx/ozLGpSkacnDAiRdLD8B1OxTbxHxItAt6ZLkrXcBNfeAwwBrSaFbCFLes7hWRESvpFuAh4EW4K6I2JZxWUOStAG4FpgjqQB8PCLuzLaqIb0d+CXgqaTvHeAPkv2qa8084G+TJy/GAV+MiJp+JLOOXAT8U/nvAsYDX4iIh7ItaVgfAe5N/jjcDfxyxvUMSdJUyk89/moq12+Gx0fNzGxozdI1ZGZmQ3AQmJk1OQeBmVmTcxCYmTU5B4GZWZNzEFjTkfRo8s/Fkn5hlK/9B4N9l1kt8+Oj1rQkXQv8ztms6CmpJSL6znD+SERMH436zMaK7wis6UiqrED6CeBHkjXefytZkO6Tkp6QtFXSrybtr032XPgC8FTy3gPJ4mrbKgusSfoEMCW53r3V36WyT0p6Olmz/31V1/5m1br49yaztZH0CUnbk1r+51j+N7Lm0hQzi82GcCtVdwTJL/SDEfEWSZOA70j6WtL2auDyiPh+cvyBiHglWariCUn3R8Stkm5JFrUb6GeBK4EVwJzkM48k51YCl1Fe/+o7wNslbQd+Brg0IqKyNIZZGnxHYPaanwBuTJbKeByYDSxLzn23KgQAPippC/AY5QUNl3FmPwxsSFY/fQn4FvCWqmsXIqIf2AwsBg4Bx4E7JP0scOy8/+3MhuAgMHuNgI9ExJXJz5KIqNwRHD3dqDy28G7gmohYAeSAySO49lBOVL3uA8ZHRC/lu5D7gZ8Gan3dHqtjDgJrZoeBGVXHDwM3J8tqI+niITYrmQkUI+KYpEuBt1WdO1X5/ACPAO9LxiHaKO+O9d2hCkv2d5iZLN73m5S7lcxS4TECa2Zbgd6ki+du4NOUu2W6kgHbHsp/jQ/0EPBrkrYCOyl3D1WsB7ZK6oqIX6x6/5+Aa4AtlDdF+r2IeDEJksHMAL4iaTLlu4nfOrd/RbPh+fFRM7Mm564hM7Mm5yAwM2tyDgIzsybnIDAza3IOAjOzJucgMDNrcg4CM7Mm9/8BUxy4W2MR81QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sse)\n",
    "plt.legend(['1e-0'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
